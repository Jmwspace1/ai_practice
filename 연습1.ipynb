{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f93f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/59/1f/4975d1ab3ed2244053876321ef65bc02935daed67da76c6e7d65900772a3/torch-2.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.2.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/e7/45/419aa0b37254f1fd62b45bb63836066c5eb81e37d70940e0491e95167eed/torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/8c/49/e37b6cacaef3fefdab3c508ef04f6cbdbfcf5c014a5ba28cb62ab33badd6/torchaudio-2.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.2.1-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.1-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/198.6 MB 26.8 MB/s eta 0:00:08\n",
      "    --------------------------------------- 2.8/198.6 MB 29.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 5.7/198.6 MB 40.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 8.6/198.6 MB 45.8 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 11.5/198.6 MB 54.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 13.6/198.6 MB 59.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 15.7/198.6 MB 54.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 15.8/198.6 MB 43.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 18.8/198.6 MB 43.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 21.7/198.6 MB 43.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 43.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 43.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 43.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 43.7 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 25.7/198.6 MB 26.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 28.6/198.6 MB 29.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 31.6/198.6 MB 29.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 33.5/198.6 MB 29.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 35.9/198.6 MB 54.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 38.8/198.6 MB 54.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 41.8/198.6 MB 50.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 44.7/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 47.6/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 50.6/198.6 MB 59.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 53.5/198.6 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 56.4/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 59.4/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 62.3/198.6 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 65.2/198.6 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 68.2/198.6 MB 65.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 71.1/198.6 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 74.0/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 76.8/198.6 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 79.8/198.6 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 82.7/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 85.7/198.6 MB 65.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 88.6/198.6 MB 59.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 91.5/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 94.5/198.6 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 97.4/198.6 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 100.3/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 103.3/198.6 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 103.8/198.6 MB 59.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 105.0/198.6 MB 43.5 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 108.0/198.6 MB 46.9 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 110.1/198.6 MB 43.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 110.1/198.6 MB 43.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 110.1/198.6 MB 43.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 110.1/198.6 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 112.4/198.6 MB 25.2 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 115.3/198.6 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 118.2/198.6 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 120.6/198.6 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 121.5/198.6 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 124.4/198.6 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 127.4/198.6 MB 46.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 130.3/198.6 MB 50.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 133.2/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 136.2/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 139.1/198.6 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 142.0/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 145.0/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 147.9/198.6 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 150.8/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 153.8/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 156.7/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 159.7/198.6 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 162.6/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 165.5/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 168.4/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 171.4/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 174.1/198.6 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 177.0/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 180.0/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 182.9/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.9/198.6 MB 59.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 188.8/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.8/198.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.9/198.6 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  194.0/198.6 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.0/198.6 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.0/198.6 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.0/198.6 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.0/198.6 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.0/198.6 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.2/198.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 198.6/198.6 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.17.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 77.0 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.2.1-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 2.2/2.4 MB 70.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 50.2 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed torch-2.2.1 torchaudio-2.2.1 torchvision-0.17.1 typing-extensions-4.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0061f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7916893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898c5049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35fea44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5953, 0.0485]])\n",
      "torch.Size([1, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1,2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b16fee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2763, 0.8283]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(1,2)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c06ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9169, 0.9141, 0.8162],\n",
      "        [0.8215, 0.6899, 0.1686],\n",
      "        [0.4712, 0.0494, 0.2136]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((3,3), dtype=torch.float)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996cd6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.uint8)\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ndarray = np.array([1,2,3], dtype=np.uint8)\n",
    "print(torch.tensor(ndarray))\n",
    "print(torch.Tensor(ndarray))\n",
    "print(torch.from_numpy(ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "012b9190",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m cpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m gpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      4\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = torch.cuda.FloatTensor([1, 2, 3])\n",
    "tensor = torch.rand((1,1), device=device)\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eacaab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m gpu \u001b[38;5;241m=\u001b[39m cpu\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      3\u001b[0m gpu2cpu \u001b[38;5;241m=\u001b[39m gpu\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m      4\u001b[0m cpu2gpu \u001b[38;5;241m=\u001b[39m cpu\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "cpu = torch.FloatTensor([1,2,3])\n",
    "gpu = cpu.cuda()\n",
    "gpu2cpu = gpu.cpu()\n",
    "cpu2gpu = cpu.to(\"cuda\")\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(gpu2cpu)\n",
    "print(cpu2gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3652c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      3\u001b[0m ndarray \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ndarray)\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.cuda.FloatTensor([1,2,3])\n",
    "ndarray = tensor.detach().cpu().numpy()\n",
    "print(ndarray)\n",
    "print(type(ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c2055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "man_height = stats.norm.rvs(loc=170, scale=10, size=500, random_state=1)\n",
    "woman_height = stats.norm.rvs(loc=150, scale=10, size=500, random_state=1)\n",
    "\n",
    "X = np.concatenate([man_height, woman_height])\n",
    "Y = [\"man\"] * len(man_height) + [\"woman\"] * len(woman_height)\n",
    "\n",
    "df = pd.DataFrame(list(zip(X, Y)), columns=[\"X\", \"Y\"])\n",
    "fig = sns.displot(data=df, x=\"X\", hue=\"Y\", kind=\"kde\")\n",
    "fig.set_axis_labels(\"cm\", \"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdd4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array(\n",
    "    [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]]\n",
    ")\n",
    "y = np.array(\n",
    "    [[0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b5cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.0\n",
    "bias = 0.0\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892c73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.872, Bias : -0.290, Cost : 1.377\n",
      "Epoch : 2000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 3000, Weight : 0.878, Bias : -0.422, Cost : 1.372\n",
      "Epoch : 4000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n",
      "Epoch : 5000, Weight : 0.879, Bias : -0.435, Cost : 1.372\n",
      "Epoch : 6000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.436, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    y_hat = weight * x + bias\n",
    "\n",
    "    cost = ((y - y_hat) ** 2).mean()\n",
    "\n",
    "    weight = weight - learning_rate * ((y_hat - y) * x).mean()\n",
    "    bias = bias - learning_rate * (y_hat - y).mean()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight:.3f}, Bias : {bias:.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51348728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ae5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610f4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.zeros(1, requires_grad=True)\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366697eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([weight, bias], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af342cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Weight : 0.864, Bias : -0.138, Cost : 1.393\n",
      "Epoch : 2000, Weight : 0.870, Bias : -0.251, Cost : 1.380\n",
      "Epoch : 3000, Weight : 0.873, Bias : -0.321, Cost : 1.375\n",
      "Epoch : 4000, Weight : 0.875, Bias : -0.364, Cost : 1.373\n",
      "Epoch : 5000, Weight : 0.877, Bias : -0.391, Cost : 1.373\n",
      "Epoch : 6000, Weight : 0.878, Bias : -0.408, Cost : 1.372\n",
      "Epoch : 7000, Weight : 0.878, Bias : -0.419, Cost : 1.372\n",
      "Epoch : 8000, Weight : 0.878, Bias : -0.425, Cost : 1.372\n",
      "Epoch : 9000, Weight : 0.879, Bias : -0.429, Cost : 1.372\n",
      "Epoch : 10000, Weight : 0.879, Bias : -0.432, Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias\n",
    "    cost = torch.mean((hypothesis - y) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Weight : {weight.item():.3f}, Bias : {bias.item():.3f}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab8c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :    1\n",
      "Step [1] : Gradient : None, Weight : 0.00000\n",
      "Step [2] : Gradient : None, Weight : 0.00000\n",
      "Step [3] : Gradient : tensor([-540.4854]), Weight : 0.00000\n",
      "Step [4] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Epoch :    2\n",
      "Step [1] : Gradient : tensor([-540.4854]), Weight : 0.54049\n",
      "Step [2] : Gradient : None, Weight : 0.54049\n",
      "Step [3] : Gradient : tensor([-198.9818]), Weight : 0.54049\n",
      "Step [4] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Epoch :    3\n",
      "Step [1] : Gradient : tensor([-198.9818]), Weight : 0.73947\n",
      "Step [2] : Gradient : None, Weight : 0.73947\n",
      "Step [3] : Gradient : tensor([-73.2604]), Weight : 0.73947\n",
      "Step [4] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Epoch :    4\n",
      "Step [1] : Gradient : tensor([-73.2604]), Weight : 0.81273\n",
      "Step [2] : Gradient : None, Weight : 0.81273\n",
      "Step [3] : Gradient : tensor([-26.9772]), Weight : 0.81273\n",
      "Step [4] : Gradient : tensor([-26.9772]), Weight : 0.83970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "\n",
    "weight = torch.zeros(1, requires_grad=True)\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = optim.SGD([weight, bias], lr=learning_rate)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hypothesis = weight * x + bias\n",
    "    cost = torch.mean((hypothesis - y) ** 2)\n",
    "    \n",
    "    print(f\"Epoch : {epoch+1:4d}\")\n",
    "    print(f\"Step [1] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    print(f\"Step [2] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    cost.backward()\n",
    "    print(f\"Step [3] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "\n",
    "    optimizer.step()\n",
    "    print(f\"Step [4] : Gradient : {weight.grad}, Weight : {weight.item():.5f}\")\n",
    "    \n",
    "    if epoch == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b768d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.8730]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3168], requires_grad=True)], Cost : 1.376\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.8753]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3618], requires_grad=True)], Cost : 1.374\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.8766]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3898], requires_grad=True)], Cost : 1.373\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.8775]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4072], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.8780]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4181], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.8784]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4248], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.8786]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4290], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.8787]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4316], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4333], requires_grad=True)], Cost : 1.372\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.8788]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4343], requires_grad=True)], Cost : 1.372\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "x = torch.FloatTensor([\n",
    "    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n",
    "    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n",
    "    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n",
    "])\n",
    "y = torch.FloatTensor([\n",
    "    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n",
    "    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n",
    "    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n",
    "])\n",
    "model = nn.Linear(1, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "for epoch in range(10000):\n",
    "    output = model(x)\n",
    "    cost = criterion(output, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1a579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.1530, 0.4826],\n",
      "        [0.4985, 0.7325]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1705, -0.2426], requires_grad=True)], Cost : 0.128\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.4213, 0.3440],\n",
      "        [0.5685, 0.6964]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5774, -0.3487], requires_grad=True)], Cost : 0.033\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[0.5580, 0.2734],\n",
      "        [0.6041, 0.6780]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7847, -0.4027], requires_grad=True)], Cost : 0.009\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[0.6277, 0.2374],\n",
      "        [0.6223, 0.6686]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8903, -0.4303], requires_grad=True)], Cost : 0.002\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[0.6631, 0.2191],\n",
      "        [0.6315, 0.6638]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9441, -0.4443], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[0.6812, 0.2097],\n",
      "        [0.6362, 0.6614]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9716, -0.4515], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[0.6904, 0.2050],\n",
      "        [0.6386, 0.6602]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9855, -0.4551], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[0.6951, 0.2026],\n",
      "        [0.6399, 0.6595]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9926, -0.4570], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[0.6975, 0.2013],\n",
      "        [0.6405, 0.6592]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9963, -0.4579], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[0.6987, 0.2007],\n",
      "        [0.6408, 0.6590]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9981, -0.4584], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[0.6993, 0.2004],\n",
      "        [0.6410, 0.6590]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9991, -0.4586], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[0.6996, 0.2002],\n",
      "        [0.6410, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9995, -0.4587], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[0.6998, 0.2001],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9998, -0.4588], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[0.6999, 0.2001],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9999, -0.4588], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[0.6999, 0.2001],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[0.6999, 0.2000],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[0.7000, 0.2000],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[0.7000, 0.2000],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[0.7000, 0.2000],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[0.7000, 0.2000],\n",
      "        [0.6411, 0.6589]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.0000, -0.4589], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "model = nn.Linear(2, 2, bias=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae1369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.5488, 0.1310],\n",
      "        [0.8072, 0.4368]], requires_grad=True)], Cost : 0.090\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[ 0.7851, -0.0601],\n",
      "        [ 0.8673,  0.3882]], requires_grad=True)], Cost : 0.056\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 0.9728, -0.2121],\n",
      "        [ 0.9150,  0.3495]], requires_grad=True)], Cost : 0.036\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 1.1220, -0.3328],\n",
      "        [ 0.9530,  0.3188]], requires_grad=True)], Cost : 0.023\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 1.2408, -0.4285],\n",
      "        [ 0.9832,  0.2945]], requires_grad=True)], Cost : 0.014\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 1.3350, -0.5048],\n",
      "        [ 1.0072,  0.2751]], requires_grad=True)], Cost : 0.009\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 1.4099, -0.5654],\n",
      "        [ 1.0262,  0.2597]], requires_grad=True)], Cost : 0.006\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 1.4694, -0.6136],\n",
      "        [ 1.0414,  0.2474]], requires_grad=True)], Cost : 0.004\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 1.5168, -0.6518],\n",
      "        [ 1.0534,  0.2377]], requires_grad=True)], Cost : 0.002\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 1.5544, -0.6823],\n",
      "        [ 1.0630,  0.2299]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[ 1.5843, -0.7064],\n",
      "        [ 1.0706,  0.2238]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[ 1.6080, -0.7256],\n",
      "        [ 1.0766,  0.2189]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[ 1.6269, -0.7409],\n",
      "        [ 1.0814,  0.2150]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[ 1.6419, -0.7530],\n",
      "        [ 1.0852,  0.2120]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[ 1.6538, -0.7627],\n",
      "        [ 1.0883,  0.2095]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[ 1.6633, -0.7703],\n",
      "        [ 1.0907,  0.2075]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[ 1.6708, -0.7764],\n",
      "        [ 1.0926,  0.2060]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[ 1.6768, -0.7813],\n",
      "        [ 1.0941,  0.2048]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[ 1.6816, -0.7851],\n",
      "        [ 1.0953,  0.2038]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[ 1.6854, -0.7882],\n",
      "        [ 1.0963,  0.2030]], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)\n",
    "model = nn.Linear(2, 2, bias=False)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cost += loss\n",
    "\n",
    "    cost = cost / len(train_dataloader)\n",
    "    \n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5ffbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a66584",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edb85fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402950ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/non_linear.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/non_linear.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/non_linear.csv'"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(\"../datasets/non_linear.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0daea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
